# AVE Speech Dataset â€“ Source Code

This repository contains the source code for *AVE Speech: A Comprehensive Multi-Modal Dataset for Speech Recognition Integrating Audio, Visual, and Electromyographic Signals*.

It will be made publicly available soon.

The dataset is available at:
ðŸ‘‰ [AVE-Speech Dataset on Hugging Face](https://huggingface.co/datasets/MML-Group/AVE-Speech)

# Citation
If you use the source code in your work, please cite it as:
```
@article{zhou2025ave,
  title={AVE Speech: A Comprehensive Multi-Modal Dataset for Speech Recognition Integrating Audio, Visual, and Electromyographic Signals},
  author={Zhou, Dongliang and Zhang, Yakun and Wu, Jinghan and Zhang, Xingyu and Xie, Liang and Yin, Erwei},
  journal={IEEE Transactions on Human-Machine Systems},
  year={2025}
}
```

# Implementation
Included codelines can be used for two speech recognition tasks, i.e., word-level continuous speech recognition (CSR) and sentence-level speech classification (CLS). 

Dataset preparation steps for mentioned tasks can be found in the CLS_fusion and CSR_fusion folders, and corresponding changes can be made to fulfill particular requirements upon your settings.  
